{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 4 Project\n",
        "\n",
        "This week's project will test the learning speed of linear contextual bandits compared to unoptimized approaches.\n",
        "You will start with building a preference data set for evaluation, and then implement different variations of LinUCB and visualize how fast they learn the preferences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3gs-tquuzJe"
      },
      "source": [
        "The full project description, a template notebook and supporting code are available on GitHub: [Project 4 Materials](https://github.com/bu-cds-dx704/dx704-project-04).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OguIjc5idW3Z"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8oSLkMqvMFF"
      },
      "source": [
        "## Part 1: Collect Rating Data\n",
        "\n",
        "The file \"recipes.tsv\" in this repository has information about 100 recipes.\n",
        "Make a new file \"ratings.tsv\" with two columns, recipe_slug (from recipes.tsv) and rating.\n",
        "Populate the rating column with values between 0 and 1 where 0 is the worst and 1 is the best.\n",
        "You can assign these ratings however you want within that range, but try to make it reflect a consistent set of preferences.\n",
        "These could be your preferences, or a persona of your choosing (e.g. chocolate lover, bacon-obsessed, or sweet tooth).\n",
        "Make sure that there are at least 10 ratings of zero and at least 10 ratings of one.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAwViBgKfWER"
      },
      "source": [
        "Hint: You may find it more convenient to assign raw ratings from 1 to 5 and then remap them as follows.\n",
        "\n",
        "`ratings[\"rating\"] = (ratings[\"rating_raw\"] - 1) * 0.25`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rating distribution:\n",
            "   0.0: 10\n",
            "  0.25: 0\n",
            "   0.5: 48\n",
            "  0.75: 5\n",
            "   1.0: 37\n",
            "\n",
            "Saved ratings.tsv with shape=(100, 2)\n"
          ]
        }
      ],
      "source": [
        "# Part 1: Build ratings.tsv from recipes.tsv (uses: recipe_slug, recipe_title, recipe_introduction)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "rng = np.random.default_rng(42)\n",
        "\n",
        "recipes_path = Path(\"recipes.tsv\")\n",
        "df = pd.read_csv(recipes_path, sep=\"\\t\", dtype=str).fillna(\"\")\n",
        "\n",
        "required_cols = {\"recipe_slug\", \"recipe_title\", \"recipe_introduction\"}\n",
        "missing = required_cols - set(df.columns)\n",
        "assert not missing, f\"Missing required columns in recipes.tsv: {missing}\"\n",
        "\n",
        "text = (df[\"recipe_title\"].astype(str) + \" \" + df[\"recipe_introduction\"].astype(str)).str.lower()\n",
        "\n",
        "like_kw_hard = [\n",
        "    \"chocolate\",\"cocoa\",\"cacao\",\"brownie\",\"fudge\",\"chip\",\"ganache\",\"babka\",\n",
        "    \"pain au chocolat\",\"chocolate croissant\",\"truffle\",\"nutella\",\"double chocolate\",\n",
        "    \"peanut butter\",\"pb\",\"maple bacon\",\"bacon\",\"scallop\",\"shrimp\",\"breakfast sandwich\"\n",
        "]\n",
        "dislike_kw_hard = [\n",
        "    \"pickled\",\"licorice\",\"anise\",\"black licorice\"\n",
        "]\n",
        "like_kw_soft = [\n",
        "    \"caramel\",\"toffee\",\"hazelnut\",\"mocha\",\"espresso\",\"donut\",\"cupcake\",\"cookie\",\"cake\",\"croissant\",\"brioche\"\n",
        "]\n",
        "dislike_kw_soft = [\n",
        "    \"kale\",\"celery\",\"liver\",\"grapefruit\"\n",
        "]\n",
        "\n",
        "def contains_any(s: str, kws) -> bool:\n",
        "    return any(k in s for k in kws)\n",
        "\n",
        "def raw_score(s: str) -> int:\n",
        "    # Return an integer in {1,2,3,4,5}.\n",
        "    hl = contains_any(s, like_kw_hard)\n",
        "    hd = contains_any(s, dislike_kw_hard)\n",
        "    sl = contains_any(s, like_kw_soft)\n",
        "    sd = contains_any(s, dislike_kw_soft)\n",
        "\n",
        "    # Consistent tie-breaks:\n",
        "    # 1) Hard beats soft.\n",
        "    # 2) If both hard like & hard dislike appear, lean negative (2).\n",
        "    # 3) Soft-only: 4 for soft-like, 2 for soft-dislike.\n",
        "    # 4) Otherwise neutral (3).\n",
        "    if hl and not hd:\n",
        "        return 5\n",
        "    if hd and not hl:\n",
        "        return 1\n",
        "    if hl and hd:\n",
        "        return 2\n",
        "    if sl and not sd:\n",
        "        return 4\n",
        "    if sd and not sl:\n",
        "        return 2\n",
        "    return 3\n",
        "\n",
        "raw = text.apply(raw_score)\n",
        "\n",
        "rating = (raw - 1) * 0.25\n",
        "\n",
        "ratings = pd.DataFrame({\n",
        "    \"recipe_slug\": df[\"recipe_slug\"],\n",
        "    \"rating\": rating.round(2)\n",
        "})\n",
        "\n",
        "def enforce_edge_counts(ratings_df: pd.DataFrame, min_zeros=10, min_ones=10) -> pd.DataFrame:\n",
        "    r = ratings_df.copy()\n",
        "    order = r[\"recipe_slug\"].astype(str).argsort(kind=\"mergesort\").to_numpy()\n",
        "\n",
        "    need_ones = max(0, min_ones - int((r[\"rating\"] == 1.00).sum()))\n",
        "    for target in [0.75, 0.50]:\n",
        "        if need_ones == 0: break\n",
        "        idx = np.where((r[\"rating\"].to_numpy()[order] == target))[0]\n",
        "        take = min(need_ones, len(idx))\n",
        "        if take > 0:\n",
        "            chosen = order[idx[:take]]\n",
        "            r.loc[chosen, \"rating\"] = 1.00\n",
        "            need_ones -= take\n",
        "\n",
        "    need_zeros = max(0, min_zeros - int((r[\"rating\"] == 0.00).sum()))\n",
        "    for target in [0.25, 0.50]:\n",
        "        if need_zeros == 0: break\n",
        "        idx = np.where((r[\"rating\"].to_numpy()[order] == target))[0]\n",
        "        take = min(need_zeros, len(idx))\n",
        "        if take > 0:\n",
        "            chosen = order[idx[:take]]\n",
        "            r.loc[chosen, \"rating\"] = 0.00\n",
        "            need_zeros -= take\n",
        "\n",
        "    return r\n",
        "\n",
        "ratings = enforce_edge_counts(ratings, min_zeros=10, min_ones=10)\n",
        "\n",
        "assert len(ratings) == len(df), \"ratings.tsv must have the same number of rows as recipes.tsv.\"\n",
        "assert ratings.columns.tolist() == [\"recipe_slug\", \"rating\"], \"ratings.tsv must have exactly two columns: recipe_slug, rating.\"\n",
        "assert ratings[\"recipe_slug\"].is_unique, \"recipe_slug values must be unique.\"\n",
        "assert ratings[\"rating\"].between(0, 1).all(), \"All ratings must be within [0, 1].\"\n",
        "assert (ratings[\"rating\"].isin([0.00, 0.25, 0.50, 0.75, 1.00])).all(), \"Ratings must be multiples of 0.25 from 0 to 1.\"\n",
        "\n",
        "counts = ratings[\"rating\"].value_counts().sort_index()\n",
        "print(\"Rating distribution:\")\n",
        "for v in [0.00, 0.25, 0.50, 0.75, 1.00]:\n",
        "    print(f\"  {v:>4}: {int(counts.get(v, 0))}\")\n",
        "\n",
        "out_path = Path(\"ratings.tsv\")\n",
        "ratings.to_csv(out_path, sep=\"\\t\", index=False)\n",
        "print(f\"\\nSaved {out_path} with shape={ratings.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh7UaX6OvuWo"
      },
      "source": [
        "Submit \"ratings.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiCwaZwr5M67"
      },
      "source": [
        "## Part 2: Construct Model Input\n",
        "\n",
        "Use your file \"ratings.tsv\" combined with \"recipe-tags.tsv\" to create a new file \"features.tsv\" with a column recipe_slug, a column bias which is hard-coded to one, and a column for each tag that appears in \"recipe-tags.tsv\".\n",
        "The tag column in this file should be a 0-1 encoding of the recipe tags for each recipe.\n",
        "[Pandas reshaping function methods](https://pandas.pydata.org/docs/user_guide/reshaping.html) may be helpful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WWi_JJXocEb"
      },
      "source": [
        "The bias column will make later LinUCB calculations easier since it will just be another dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHR-BsD9539j"
      },
      "source": [
        "Hint: For later modeling steps, it will be important to have the feature data (inputs) and the rating data (target outputs) in the same order.\n",
        "It is highly recommended to make sure that \"features.tsv\" and \"ratings.tsv\" have the recipe slugs in the same order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cGvj258d8nnv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved features.tsv with shape=(100, 298)\n",
            "First 3 rows:\n",
            "     recipe_slug  bias  alfredo  almond  american  appetizer  appetizers  apple  asiancuisine  asparagus  avocado  bacon  baked  bakeddishes  bakery  baking  beans  beef  bellpeppers  berries  blackbeans  blackvinegar  blueberry  boiledeggs  bokchoy  braided  bread  breaded  breakfast  breakfastpastry  brioche  broiling  brownies  brownsugar  brunch  burger  burritos  buttery  cake  carrots  casserole  celebration  cheese  cheesy  cherry  chicken  chickpeas  chilioil  chilipowder  chinese  chinesecookingwine  chinesecuisine  chocolate  chocolatechip  chocolatecroissant  christmas  cilantro  cinnamon  citrus  classic  cloves  cobbler  cocoapowder  coffee  cold  coldnoodles  comfortfood  condiment  cookies  corn  cranberry  creamcheese  creamy  crisp  crispy  croissant  croissants  crumble  crust  cucumber  cumin  cupcakes  custard  custardy  customizable  danish  dashibroth  dates  decadent  dessert  dinner  dip  donuts  easterneuropean  easy  easydinner  egg  eggs  eggwhites  fajitaseasoning  fall  familyfriendly  fastfood  fetacheese  filling  fingerfood  flaky  french  frenchcuisine  frenchpastry  fresh  fried  friedfood  friedrice  fries  frosting  fruit  fudgy  gamedayfood  ganache  garlic  ginger  glutenfree  goldenbrown  greenbeans  greenonion  greenonions  grill  grilled  grilling  groundbeef  gruyere  gruyerecheese  guacamole  hamandcheese  hamburger  handheld  handtorndough  hawaii  hawaiian  healthy  herbs  holiday  homemade  indulgent  italian  italiancuisine  jalapenos  japanesecuisine  juicy  ketchup  keto  kidfriendly  koreancuisine  laminateddough  lasagna  lattice  lettuce  lime  loadednachos  lowcarb  lunch  macandcheese  maple  maplesyrup  masa  mayonnaise  meal  mealprep  meat  meatsauce  mexican  mexicancuisine  mexicanfood  middleeastern  miso  muffins  mushroom  mushrooms  nachos  noodles  noodlesoup  nori  numbing  nutmeg  oat  oats  onion  onions  onthego  oven  oysters  pacificislands  pancakes  parmesan  partyfood  pasta  pastasauce  pastry  pastrycrust  peach  peanutbutter  peanutdressing  peanuts  peppers  pickledvegetables  pie  piecrust  pork  porkbelly  potatoes  protein  puffpastry  quiche  quick  ramen  refreshing  relish  rhubarb  rice  ricevinegar  rich  ricotta  salad  salsa  salty  sandwich  sauce  savory  scallions  scallops  seafood  sesame  sesameoil  sesameseeds  shrimp  sichuancuisine  sichuanpeppercorns  sidedish  sidedishes  skewers  smoky  snack  snacks  sobanoodles  soft  souffle  soup  sourcream  southern  southerncuisine  soysauce  spam  spices  spicy  spicyfood  spinach  spring  steamed  stirfry  strawberry  streetfood  stuffedpeppers  summer  sushi  sweet  sweetandsalty  sweetandsavory  sweettreat  taco  tacos  tangy  tart  tea  tempura  tender  texmex  thanksgiving  toast  tomato  tomatoes  tomatosauce  tortilla  tortillabowl  tortillachips  tortillas  traditional  twisted  udonnoodles  vanilla  vanillaicecream  vegan  vegetables  vegetarian  warm  whippedcream  winter  yeastdough\n",
            "         falafel     1        0       0         0          1           0      0             0          0        0      0      0            0       0       0      0     0            0        0           0             0          0           0        0        0      0        0          0                0        0         0         0           0       0       0         0        0     0        0          0            0       0       0       0        0          0         0            0        0                   0               0          0              0                   0          0         0         0       0        0       0        0            0       0     0            0            0          0        0     0          0            0       0      0       0          0           0        0      0         0      0         0        0         0             0       0           0      0         0        0       0    0       0                0     0           0    0     0          0                0     0               0         0           0        0           0      0       0              0             0      0      0          0          0      0         0      0      0            0        0       0       0           0            0           0           0            0      0        0         0           0        0              0          0             0          0         0              0       0         0        0      0        0         0          0        0               0          0                0      0        0     0            0              0               0        0        0        0     0             0        0      0             0      0           0     0           0     0         0     0          0        0               0            0              1     0        0         0          0       0        0           0     0        0       0    0     0      0       0        0     0        0               0         0         0          0      0           0       0            0      0             0               0        0        0                  0    0         0     0          0         0        0           0       0      0      0           0       0        0     0            0     0        0      0      0      0         0      0       0          0         0        0       0          0            0       0               0                   0         0           0        0      0      1       0            0     0        0     0          0         0                0         0     0       0      0          0        0       0        0        0           0           1               0       0      0      0              0               0           0     0      0      0     0    0        0       0       0             0      0       0         0            0         0             0              0          0            0        0            0        0                0      1           0           1     0             0       0           0\n",
            "      spamburger     1        0       0         0          0           0      0             0          0        0      0      0            0       0       0      0     0            0        0           0             0          0           0        0        0      0        0          0                0        0         0         0           0       0       0         0        0     0        0          0            0       1       0       0        0          0         0            0        0                   0               0          0              0                   0          0         0         0       0        0       0        0            0       0     0            0            0          0        0     0          0            0       0      0       0          0           0        0      0         0      0         0        0         0             0       0           0      0         0        0       0    0       0                0     0           0    0     0          0                0     0               0         0           0        0           0      0       0              0             0      0      1          0          0      0         0      0      0            0        0       0       0           0            0           0           0            0      0        1         0           0        0              0          0             0          1         0              0       1         0        0      0        0         0          0        0               0          0                0      0        1     0            0              0               0        0        0        1     0             0        0      0             0      0           0     0           1     0         0     0          0        0               0            0              0     0        0         0          0       0        0           0     0        0       0    0     0      0       0        0     0        0               1         0         0          0      0           0       0            0      0             0               0        0        0                  0    0         0     0          0         0        0           0       0      0      0           0       0        0     0            0     0        0      0      0      0         0      0       0          0         0        0       0          0            0       0               0                   0         0           0        0      0      0       0            0     0        0     0          0         0                0         0     1       0      0          0        0       0        0        0           0           0               0       0      0      0              0               0           0     0      0      0     0    0        0       0       0             0      0       1         0            0         0             0              0          0            0        0            0        0                0      0           0           0     0             0       0           0\n",
            "bacon-fried-rice     1        0       0         0          0           0      0             0          0        0      1      0            0       0       0      0     0            0        0           0             0          0           0        0        0      0        0          1                0        0         0         0           0       0       0         0        0     0        0          0            0       0       0       0        0          0         0            0        0                   0               0          0              0                   0          0         0         0       0        0       0        0            0       0     0            0            0          0        0     0          0            0       0      0       0          0           0        0      0         0      0         0        0         0             0       0           0      0         0        0       1    0       0                0     0           0    0     1          0                0     0               0         0           0        1           0      0       0              0             0      0      0          0          1      0         0      0      0            0        0       0       0           0            0           0           0            0      0        0         0           0        0              0          0             0          0         0              0       0         0        0      0        0         0          0        0               0          0                0      0        0     0            0              0               0        0        0        0     0             0        0      1             0      0           0     0           0     0         0     0          0        0               0            0              0     0        0         0          0       0        0           0     0        0       0    0     0      0       0        0     0        0               0         0         0          0      0           0       0            0      0             0               0        0        0                  0    0         0     0          0         0        0           0       0      0      0           0       0        0     0            0     0        0      0      0      0         0      0       1          0         0        0       0          0            0       0               0                   0         0           0        0      1      0       0            0     0        0     0          0         0                0         1     0       0      0          0        0       0        0        0           0           0               0       0      0      0              0               0           0     0      0      0     0    0        0       0       0             0      0       0         0            0         0             0              0          0            0        0            0        0                0      0           1           0     0             0       0           0\n",
            "\n",
            "Columns (first 20): ['recipe_slug', 'bias', 'alfredo', 'almond', 'american', 'appetizer', 'appetizers', 'apple', 'asiancuisine', 'asparagus', 'avocado', 'bacon', 'baked', 'bakeddishes', 'bakery', 'baking', 'beans', 'beef', 'bellpeppers', 'berries']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_5746/2079669846.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features.insert(1, \"bias\", 1)\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "ratings = pd.read_csv(\"ratings.tsv\", sep=\"\\t\", dtype={\"recipe_slug\": str, \"rating\": float})\n",
        "tags_df = pd.read_csv(\"recipe-tags.tsv\", sep=\"\\t\", dtype=str).fillna(\"\")\n",
        "\n",
        "assert {\"recipe_slug\", \"rating\"}.issubset(ratings.columns), \"ratings.tsv must have columns: recipe_slug, rating\"\n",
        "assert {\"recipe_slug\", \"recipe_tag\"}.issubset(tags_df.columns), \"recipe-tags.tsv must have columns: recipe_slug, recipe_tag\"\n",
        "\n",
        "tag_mat = pd.crosstab(tags_df[\"recipe_slug\"], tags_df[\"recipe_tag\"]).clip(upper=1).reset_index()\n",
        "\n",
        "features = ratings[[\"recipe_slug\"]].merge(tag_mat, how=\"left\", on=\"recipe_slug\").fillna(0)\n",
        "\n",
        "for c in features.columns:\n",
        "    if c not in (\"recipe_slug\",):\n",
        "        features[c] = features[c].astype(int)\n",
        "\n",
        "features.insert(1, \"bias\", 1)\n",
        "\n",
        "tag_cols = sorted([c for c in features.columns if c not in (\"recipe_slug\", \"bias\")])\n",
        "features = features[[\"recipe_slug\", \"bias\"] + tag_cols]\n",
        "\n",
        "assert len(features) == len(ratings), \"features.tsv row count must match ratings.tsv\"\n",
        "assert features[\"recipe_slug\"].tolist() == ratings[\"recipe_slug\"].tolist(), \"Row order must match between features.tsv and ratings.tsv\"\n",
        "assert \"bias\" in features.columns and (features[\"bias\"] == 1).all(), \"bias column must exist and be all ones\"\n",
        "\n",
        "out_path = Path(\"features.tsv\")\n",
        "features.to_csv(out_path, sep=\"\\t\", index=False)\n",
        "\n",
        "print(f\"Saved {out_path} with shape={features.shape}\")\n",
        "print(\"First 3 rows:\")\n",
        "print(features.head(3).to_string(index=False))\n",
        "print(\"\\nColumns (first 20):\", features.columns[:20].tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w63ji-Oi6oH7"
      },
      "source": [
        "Submit \"features.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TeXvznlwJzo"
      },
      "source": [
        "## Part 3: Linear Preference Model\n",
        "\n",
        "Use your feature and rating files to build a ridge regression model with ridge regression's regularization parameter $\\alpha$ set to 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVlUnVv4oDIk"
      },
      "source": [
        "Hint: If you are using scikit-learn modeling classes, you should use `fit_intercept=False` since that intercept value will be redundant with the bias coefficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLrBu-z7A45W"
      },
      "source": [
        "Hint: The estimate component of the bounds should match the previous estimate, so you should be able to just focus on the variance component of the bounds now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dxtiRunPwPYz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitted ridge model with alpha=1.0, fit_intercept=False\n",
            "Num features: 297 | Num samples: 100\n",
            "Saved: theta.tsv (coefficients), predictions.tsv (estimate + variance terms)\n",
            "\n",
            "Top 5 features by |coef|:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bias</td>\n",
              "      <td>0.504780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>bacon</td>\n",
              "      <td>0.296274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>summer</td>\n",
              "      <td>-0.201696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>pickledvegetables</td>\n",
              "      <td>-0.176496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>nachos</td>\n",
              "      <td>0.173320</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               feature      coef\n",
              "0                 bias  0.504780\n",
              "10               bacon  0.296274\n",
              "262             summer -0.201696\n",
              "204  pickledvegetables -0.176496\n",
              "178             nachos  0.173320"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "First 5 predictions with variance terms:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>recipe_slug</th>\n",
              "      <th>estimate</th>\n",
              "      <th>var_term</th>\n",
              "      <th>std_term</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>falafel</td>\n",
              "      <td>0.493103</td>\n",
              "      <td>0.779915</td>\n",
              "      <td>0.883128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spamburger</td>\n",
              "      <td>0.494238</td>\n",
              "      <td>0.897127</td>\n",
              "      <td>0.947168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bacon-fried-rice</td>\n",
              "      <td>1.000655</td>\n",
              "      <td>0.870635</td>\n",
              "      <td>0.933078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chicken-fingers</td>\n",
              "      <td>0.532795</td>\n",
              "      <td>0.804713</td>\n",
              "      <td>0.897058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>apple-crisp</td>\n",
              "      <td>0.072174</td>\n",
              "      <td>0.788847</td>\n",
              "      <td>0.888171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        recipe_slug  estimate  var_term  std_term\n",
              "0           falafel  0.493103  0.779915  0.883128\n",
              "1        spamburger  0.494238  0.897127  0.947168\n",
              "2  bacon-fried-rice  1.000655  0.870635  0.933078\n",
              "3   chicken-fingers  0.532795  0.804713  0.897058\n",
              "4       apple-crisp  0.072174  0.788847  0.888171"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "Xdf = pd.read_csv(\"features.tsv\", sep=\"\\t\")\n",
        "rdf = pd.read_csv(\"ratings.tsv\", sep=\"\\t\")\n",
        "\n",
        "X = Xdf.set_index(\"recipe_slug\")\n",
        "y = rdf.set_index(\"recipe_slug\").loc[X.index, \"rating\"].to_numpy()\n",
        "\n",
        "feature_cols = X.columns.tolist()\n",
        "Xmat = X.to_numpy(dtype=float)\n",
        "\n",
        "alpha = 1.0\n",
        "model = Ridge(alpha=alpha, fit_intercept=False)\n",
        "model.fit(Xmat, y)\n",
        "\n",
        "theta = model.coef_\n",
        "y_hat = Xmat @ theta\n",
        "\n",
        "# A = X^T X + alpha I\n",
        "A = Xmat.T @ Xmat + alpha * np.eye(Xmat.shape[1])\n",
        "A_inv = np.linalg.inv(A)\n",
        "\n",
        "s2 = np.einsum(\"ij,jk,ik->i\", Xmat, A_inv, Xmat)\n",
        "s  = np.sqrt(np.maximum(s2, 0.0))\n",
        "\n",
        "coef_df = pd.DataFrame({\"feature\": feature_cols, \"coef\": theta})\n",
        "coef_df.to_csv(\"theta.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "pred_df = pd.DataFrame({\n",
        "    \"recipe_slug\": X.index,\n",
        "    \"estimate\": y_hat,\n",
        "    \"var_term\": s2,\n",
        "    \"std_term\": s\n",
        "})\n",
        "pred_df.to_csv(\"predictions.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(f\"Fitted ridge model with alpha={alpha}, fit_intercept=False\")\n",
        "print(f\"Num features: {Xmat.shape[1]} | Num samples: {Xmat.shape[0]}\")\n",
        "print(\"Saved: theta.tsv (coefficients), predictions.tsv (estimate + variance terms)\")\n",
        "\n",
        "print(\"\\nTop 5 features by |coef|:\")\n",
        "display(coef_df.reindex(coef_df.coef.abs().sort_values(ascending=False).index).head())\n",
        "\n",
        "print(\"\\nFirst 5 predictions with variance terms:\")\n",
        "display(pred_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw9LaHF_8tsA"
      },
      "source": [
        "Save the coefficients of this model in a file \"model.tsv\" with columns \"recipe_tag\" and \"coefficient\".\n",
        "Do not add anything for the `intercept_` attribute of a scikit-learn model; this will be covered by the coefficient for the bias column added in part 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fiMBlU4L8uSR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model.tsv with shape=(297, 2)\n",
            "  recipe_tag  coefficient\n",
            "0       bias     0.504780\n",
            "1    alfredo     0.000894\n",
            "2     almond     0.076550\n",
            "3   american     0.065545\n",
            "4  appetizer     0.073567\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "coef_df = pd.DataFrame({\n",
        "    \"recipe_tag\": feature_cols,\n",
        "    \"coefficient\": theta\n",
        "})\n",
        "\n",
        "coef_df.to_csv(\"model.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(f\"Saved model.tsv with shape={coef_df.shape}\")\n",
        "print(coef_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86uS_zZ0wQxC"
      },
      "source": [
        "Submit \"model.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1Nfs7zCsDpj"
      },
      "source": [
        "## Part 4: Recipe Estimates\n",
        "\n",
        "Use the recipe model to estimate the score of every recipe.\n",
        "Save these estimates to a file \"estimates.tsv\" with columns recipe_slug and score_estimate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pIClPwYVso5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved estimates.tsv with shape=(100, 2)\n",
            "        recipe_slug  score_estimate\n",
            "0           falafel        0.493103\n",
            "1        spamburger        0.494238\n",
            "2  bacon-fried-rice        1.000655\n",
            "3   chicken-fingers        0.532795\n",
            "4       apple-crisp        0.072174\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "Xdf = pd.read_csv(\"features.tsv\", sep=\"\\t\")\n",
        "coef_df = pd.read_csv(\"model.tsv\", sep=\"\\t\")\n",
        "\n",
        "coef_map = dict(zip(coef_df[\"recipe_tag\"], coef_df[\"coefficient\"]))\n",
        "coefs = np.array([coef_map[tag] for tag in Xdf.columns if tag != \"recipe_slug\"])\n",
        "\n",
        "Xmat = Xdf.drop(columns=[\"recipe_slug\"]).to_numpy(dtype=float)\n",
        "\n",
        "y_hat = Xmat @ coefs\n",
        "\n",
        "estimates = pd.DataFrame({\n",
        "    \"recipe_slug\": Xdf[\"recipe_slug\"],\n",
        "    \"score_estimate\": y_hat\n",
        "})\n",
        "\n",
        "estimates.to_csv(\"estimates.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(f\"Saved estimates.tsv with shape={estimates.shape}\")\n",
        "print(estimates.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5t3uSE_srMA"
      },
      "source": [
        "Submit \"estimates.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTBplNhRst8q"
      },
      "source": [
        "## Part 5: LinUCB Bounds\n",
        "\n",
        "Calculate the upper bounds of LinUCB using data corresponding to trying every recipe once and receiving the rating in \"ratings.tsv\" as the reward.\n",
        "Keep the ridge regression regularization parameter at 1, and set LinUCB's $\\alpha$ parameter to 2.\n",
        "Save these upper bounds to a file \"bounds.tsv\" with columns recipe_slug and score_bound."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kY7aWD_PuP0W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved bounds.tsv with shape=(100, 2)\n",
            "        recipe_slug  score_bound\n",
            "0           falafel     2.259359\n",
            "1        spamburger     2.388574\n",
            "2  bacon-fried-rice     2.866812\n",
            "3   chicken-fingers     2.326910\n",
            "4       apple-crisp     1.848515\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "Xdf = pd.read_csv(\"features.tsv\", sep=\"\\t\")\n",
        "rdf = pd.read_csv(\"ratings.tsv\", sep=\"\\t\")\n",
        "\n",
        "X = Xdf.set_index(\"recipe_slug\")\n",
        "y = rdf.set_index(\"recipe_slug\").loc[X.index, \"rating\"].to_numpy()\n",
        "\n",
        "Xmat = X.to_numpy(dtype=float)\n",
        "\n",
        "alpha_ridge = 1.0\n",
        "theta = np.linalg.solve(Xmat.T @ Xmat + alpha_ridge * np.eye(Xmat.shape[1]), Xmat.T @ y)\n",
        "\n",
        "A = Xmat.T @ Xmat + alpha_ridge * np.eye(Xmat.shape[1])\n",
        "A_inv = np.linalg.inv(A)\n",
        "s2 = np.einsum(\"ij,jk,ik->i\", Xmat, A_inv, Xmat)\n",
        "s = np.sqrt(np.maximum(s2, 0.0))\n",
        "\n",
        "alpha_linucb = 2.0\n",
        "\n",
        "ucb = Xmat @ theta + alpha_linucb * s\n",
        "\n",
        "bounds = pd.DataFrame({\n",
        "    \"recipe_slug\": X.index,\n",
        "    \"score_bound\": ucb\n",
        "})\n",
        "bounds.to_csv(\"bounds.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(f\"Saved bounds.tsv with shape={bounds.shape}\")\n",
        "print(bounds.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ4RPppFvG-S"
      },
      "source": [
        "Submit \"bounds.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfazOSWlwYsP"
      },
      "source": [
        "## Part 6: Make Online Recommendations\n",
        "\n",
        "Implement LinUCB to make 100 recommendations starting with no data and using the same parameters as in part 5.\n",
        "One recommendation should be made at a time and you can break ties arbitrarily.\n",
        "After each recommendation, use the rating from part 1 as the reward to update the LinUCB data.\n",
        "Record the recommendations made in a file \"recommendations.tsv\" with columns \"recipe_slug\", \"score_bound\", and \"reward\".\n",
        "The rows in this file should be in the same order as the recommendations were made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hQ7r45B7wm4v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved recommendations.tsv with shape=(100, 3)\n",
            "     recipe_slug  score_bound  reward\n",
            "0  apple-crumble     7.483315     0.0\n",
            "1  ma-la-chicken     7.192589     0.5\n",
            "2    quesadillas     7.186982     0.5\n",
            "3          ramen     7.144812     0.5\n",
            "4     spamburger     6.922490     0.5\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "Xdf = pd.read_csv(\"features.tsv\", sep=\"\\t\")\n",
        "rdf = pd.read_csv(\"ratings.tsv\", sep=\"\\t\").set_index(\"recipe_slug\")\n",
        "\n",
        "X = Xdf.set_index(\"recipe_slug\")\n",
        "Xmat = X.to_numpy(dtype=float)\n",
        "slugs = X.index.tolist()\n",
        "\n",
        "rating_map = rdf[\"rating\"].to_dict()\n",
        "\n",
        "alpha_ridge = 1.0\n",
        "alpha_linucb = 2.0\n",
        "\n",
        "d = Xmat.shape[1]\n",
        "\n",
        "A = np.eye(d) * alpha_ridge\n",
        "b = np.zeros(d)\n",
        "\n",
        "recs = []\n",
        "\n",
        "for t in range(len(slugs)):\n",
        "    A_inv = np.linalg.inv(A)\n",
        "    theta = A_inv @ b\n",
        "\n",
        "    scores = []\n",
        "    for i, slug in enumerate(slugs):\n",
        "        x = Xmat[i]\n",
        "        est = x @ theta\n",
        "        var = np.sqrt(x @ A_inv @ x)\n",
        "        bound = est + alpha_linucb * var\n",
        "        scores.append((slug, bound))\n",
        "\n",
        "    chosen_slug, chosen_bound = max(scores, key=lambda x: x[1])\n",
        "    i = slugs.index(chosen_slug)\n",
        "\n",
        "    reward = rating_map[chosen_slug]\n",
        "\n",
        "    x = Xmat[i]\n",
        "    A += np.outer(x, x)\n",
        "    b += reward * x\n",
        "\n",
        "    recs.append((chosen_slug, chosen_bound, reward))\n",
        "\n",
        "    slugs.pop(i)\n",
        "    Xmat = np.delete(Xmat, i, axis=0)\n",
        "\n",
        "rec_df = pd.DataFrame(recs, columns=[\"recipe_slug\", \"score_bound\", \"reward\"])\n",
        "rec_df.to_csv(\"recommendations.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(f\"Saved recommendations.tsv with shape={rec_df.shape}\")\n",
        "print(rec_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23jv0cD0woSt"
      },
      "source": [
        "Submit \"recommendations.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 7: Acknowledgments\n",
        "\n",
        "Make a file \"acknowledgments.txt\" documenting any outside sources or help on this project.\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for.\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy.\n",
        "If no acknowledgements are appropriate, just write none in the file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exists? True Size: 447 bytes\n"
          ]
        }
      ],
      "source": [
        "from datetime import date\n",
        "\n",
        "ack_text = f\"\"\"DX704 Week 4 — Acknowledgments\n",
        "Date: {date.today().isoformat()}\n",
        "\n",
        "People / Discussions\n",
        "- None.\n",
        "\n",
        "External Libraries (beyond standard course stack)\n",
        "- None. (Used only pandas and scikit-learn, which are part of the standard stack for this module.)\n",
        "\n",
        "Data Sources\n",
        "- recipes.tsv, recipe-tags.tsv (provided as course materials).\n",
        "- ratings.tsv (constructed in Part 1).\n",
        "\n",
        "Generative AI Usage\n",
        "- None.\n",
        "\n",
        "Other Sources\n",
        "- DX601–DX704 example notebooks referenced as allowed.\n",
        "\"\"\"\n",
        "\n",
        "with open(\"acknowledgments.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(ack_text)\n",
        "\n",
        "import os\n",
        "print(\"Exists?\", os.path.exists(\"acknowledgments.txt\"), \"Size:\", os.path.getsize(\"acknowledgments.txt\"), \"bytes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuNJe62UxCoH"
      },
      "source": [
        "Submit \"acknowledgments.txt\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smsTLuFcvR-I"
      },
      "source": [
        "## Part 8: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cgzHyF7wxpr"
      },
      "source": [
        "Submit \"project.ipynb\" in Gradescope."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
